{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56497f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e556d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y6/z9h695vx2w3gbjh7z32h4j9m0000gn/T/ipykernel_15157/3016886942.py:4: DtypeWarning: Columns (24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_193 = pd.read_csv(\"/Users/wooyongjung/WJ_Projects/C2P_Project/Data/UAS/uas193.csv\")\n",
      "/var/folders/y6/z9h695vx2w3gbjh7z32h4j9m0000gn/T/ipykernel_15157/3016886942.py:5: DtypeWarning: Columns (24,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_308 = pd.read_csv(\"/Users/wooyongjung/WJ_Projects/C2P_Project/Data/UAS/uas308.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Load the required datasets for abortion from UAS\n",
    "df_myhh = pd.read_csv(\"/Users/wooyongjung/WJ_Projects/C2P_Project/Data/UAS/myhousehold.csv\")\n",
    "df_125 = pd.read_csv(\"/Users/wooyongjung/WJ_Projects/C2P_Project/Data/UAS/uas125.csv\")\n",
    "df_193 = pd.read_csv(\"/Users/wooyongjung/WJ_Projects/C2P_Project/Data/UAS/uas193.csv\")\n",
    "df_308 = pd.read_csv(\"/Users/wooyongjung/WJ_Projects/C2P_Project/Data/UAS/uas308.csv\")\n",
    "df_621 = pd.read_csv(\"/Users/wooyongjung/WJ_Projects/C2P_Project/Data/UAS/uas621.csv\")\n",
    "df_645 = pd.read_csv(\"/Users/wooyongjung/WJ_Projects/C2P_Project/Data/UAS/uas645.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43bcb350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns from myhousehold.csv\n",
    "myhh_columns = [\"uasid\", \"citizenus\", \"bornus\", \"gender\", \"dateofbirth_year\", \"race\"]\n",
    "basic_columns = [\"uasid\", \"start_year\", \"start_month\", \"age\", \"statereside\", \n",
    "                 \"maritalstatus\", \"education\", \"laborstatus\", \"employmenttype\", \"hhincome\", \"hourswork\", \"hhmembernumber\"]\n",
    "\n",
    "# Add specific columns for each dataset\n",
    "uas125_columns = basic_columns + [\"tg_004\"]\n",
    "uas193_columns = basic_columns + [\"ab_001\"]\n",
    "uas308_columns = basic_columns + [\"sc_18\"]\n",
    "uas621_columns = basic_columns + [\"cn001f\", \"at001f\"]\n",
    "uas645_columns = basic_columns + [\"v003d\"]\n",
    "\n",
    "# Select relevant columns from each dataset\n",
    "df_myhh = df_myhh[myhh_columns]\n",
    "df_125 = df_125[uas125_columns]\n",
    "df_193 = df_193[uas193_columns]\n",
    "df_308 = df_308[uas308_columns]\n",
    "df_621 = df_621[uas621_columns]\n",
    "df_645 = df_645[uas645_columns]\n",
    "\n",
    "# Rename columns for clarity\n",
    "df_125.rename(columns={\n",
    "    \"start_year\": \"year_125\",\n",
    "    \"start_month\": \"month_125\",\n",
    "    \"age\": \"age_125\",\n",
    "    \"statereside\": \"statereside_125\",\n",
    "    \"maritalstatus\": \"maritalstatus_125\",\n",
    "    \"education\": \"education_125\",\n",
    "    \"laborstatus\": \"laborstatus_125\",\n",
    "    \"employmenttype\": \"employmenttype_125\",\n",
    "    \"hhincome\": \"hhincome_125\",\n",
    "    \"hourswork\": \"hourswork_125\",\n",
    "    \"hhmembernumber\": \"hhmembernumber_125\",\n",
    "    \"tg_004\": \"abortion_2018_Apr\"\n",
    "}, inplace=True)\n",
    "\n",
    "df_193.rename(columns={\n",
    "    \"start_year\": \"year_193\",\n",
    "    \"start_month\": \"month_193\",\n",
    "    \"age\": \"age_193\",\n",
    "    \"statereside\": \"statereside_193\",\n",
    "    \"maritalstatus\": \"maritalstatus_193\",\n",
    "    \"education\": \"education_193\",\n",
    "    \"laborstatus\": \"laborstatus_193\",\n",
    "    \"employmenttype\": \"employmenttype_193\",\n",
    "    \"hhincome\": \"hhincome_193\",\n",
    "    \"hourswork\": \"hourswork_193\",\n",
    "    \"hhmembernumber\": \"hhmembernumber_193\",\n",
    "    \"ab_001\": \"abortion_2019_Jul\"\n",
    "}, inplace=True)\n",
    "\n",
    "\n",
    "df_308.rename(columns={\n",
    "    \"start_year\": \"year_308\",\n",
    "    \"start_month\": \"month_308\",\n",
    "    \"age\": \"age_308\",\n",
    "    \"statereside\": \"statereside_308\",\n",
    "    \"maritalstatus\": \"maritalstatus_308\",\n",
    "    \"education\": \"education_308\",\n",
    "    \"laborstatus\": \"laborstatus_308\",\n",
    "    \"employmenttype\": \"employmenttype_308\",\n",
    "    \"hhincome\": \"hhincome_308\",\n",
    "    \"hourswork\": \"hourswork_308\",\n",
    "    \"hhmembernumber\": \"hhmembernumber_308\",\n",
    "    \"sc_18\": \"abortion_2020_Sep\"\n",
    "}, inplace=True)\n",
    "\n",
    "df_621.rename(columns={\n",
    "    \"start_year\": \"year_621\",\n",
    "    \"start_month\": \"month_621\",\n",
    "    \"age\": \"age_621\",\n",
    "    \"statereside\": \"statereside_621\",\n",
    "    \"maritalstatus\": \"maritalstatus_621\",\n",
    "    \"education\": \"education_621\",\n",
    "    \"laborstatus\": \"laborstatus_621\",\n",
    "    \"employmenttype\": \"employmenttype_621\",\n",
    "    \"hhincome\": \"hhincome_621\",\n",
    "    \"hourswork\": \"hourswork_621\",\n",
    "    \"hhmembernumber\": \"hhmembernumber_621\",\n",
    "    \"at001f\": \"abortion_2024_Aug\"\n",
    "}, inplace=True)\n",
    "\n",
    "df_645.rename(columns={\n",
    "    \"start_year\": \"year_645\",\n",
    "    \"start_month\": \"month_645\",\n",
    "    \"age\": \"age_645\",\n",
    "    \"statereside\": \"statereside_645\",\n",
    "    \"maritalstatus\": \"maritalstatus_645\",\n",
    "    \"education\": \"education_645\",\n",
    "    \"laborstatus\": \"laborstatus_645\",\n",
    "    \"employmenttype\": \"employmenttype_645\",\n",
    "    \"hhincome\": \"hhincome_645\",\n",
    "    \"hourswork\": \"hourswork_645\",\n",
    "    \"hhmembernumber\": \"hhmembernumber_645\",\n",
    "    \"v003d\": \"abortion_2024_Nov\"\n",
    "}, inplace=True)\n",
    "\n",
    "# Merge datasets on 'uasid'\n",
    "df_abortion = df_125.merge(df_193, on=\"uasid\", how=\"outer\") \\\n",
    "                    .merge(df_308, on=\"uasid\", how=\"outer\") \\\n",
    "                    .merge(df_621, on=\"uasid\", how=\"outer\") \\\n",
    "                    .merge(df_645, on=\"uasid\", how=\"outer\") \\\n",
    "                    .merge(df_myhh, on=\"uasid\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y6/z9h695vx2w3gbjh7z32h4j9m0000gn/T/ipykernel_15157/77948821.py:2: DtypeWarning: Columns (87,88,132,133,5916,5917,5938,5939,5961,5962,9063,9064,9065,9066,9067,9068,9069,9070,9071,9072,9073,9074,9075,9077,9079,9080,9081,9082,9083,9084,9086,9087,9088,9089,9090,9126,9127,9140,9141,9154,9155,9168,9169,9203,9204,9205,9206,9207,9208,9209,9210,9211,9212,9213,9214,9215,9216,9217,9218,9219,9220,9221,9222,9223,9224,9225,9226,9227,9228,9229,9230,9231,9232,9233,9234,9235,9236,9237,9238,9239,9240,9241,9242,9243,9244,9245,9246,9248,9249,9250,9251,9252,9253,9254,9255,9256,9257,9258,9259,9260,9261,9262,9263,9264,9265,9266,9267,9268,9269,9272,9273,9274,9275,9278,9279,9280,9281,9282,9283,9284,9285,9286,9287,9288,9289,9290,9291,9292,9293,9294,9295,9296,9297,9298,9299,9300,9301,9302,9303,9304,9305,9306,9307,9308,9309,9310,9311,9312,9313,9314,9315,9316,9317,9318,9319,9320,9321,9322,9323,9325,9326,9327,9328,9329,9330,9331,9332,9333,9334,9335,9336,9337,9338,9339,9340,9341,9342,9343,9344,9345,9346,9349,9350,9351,9352,9355,9356,9448,9449,9450,9451,9452,9453,9454,9455,9456,9457) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_comprehensive = pd.read_csv(\"/Users/wooyongjung/WJ_Projects/C2P_Project/Data/UAS/uas_comprehensive525.csv\")\n",
      "/var/folders/y6/z9h695vx2w3gbjh7z32h4j9m0000gn/T/ipykernel_15157/77948821.py:172: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df_abortion_comp = df_abortion_comp.applymap(lambda x: None if str(x).startswith('.') else x)\n"
     ]
    }
   ],
   "source": [
    "# Add UAS comprehensive file\n",
    "df_comprehensive = pd.read_csv(\"/Users/wooyongjung/WJ_Projects/C2P_Project/Data/UAS/uas_comprehensive525.csv\")\n",
    "\n",
    "# Select relevant columns from the comprehensive file\n",
    "comprehensive_columns = [\"uasid\", \n",
    "                         \"h12child\", \"h13child\", \"h14child\", \"h15child\", \"h16child\", \n",
    "                         \"h12itot\", \"h13itot\", \"h14itot\", \"h15itot\", \"h16itot\", \n",
    "                         \"r12mstat\", \"r13mstat\", \"r14mstat\", \"r15mstat\", \"r16mstat\",\n",
    "                         \"r12educ\", \"r13educ\", \"r14educ\", \"r15educ\", \"r16educ\",\n",
    "                         \"rarelig\",\n",
    "                         \"r12laborstatus\", \"r13laborstatus\", \"r14laborstatus\", \"r15laborstatus\", \"r16laborstatus\",\n",
    "                         \"r12stateres\", \"r13stateres\", \"r14stateres\", \"r15stateres\", \"r16stateres\",\n",
    "                         \"r12jcoccc\", \"r13jcoccc\", \"r14jcoccc\", \"r15jcoccc\", \n",
    "                         \"r12urbanicity\", \"r13urbanicity\", \"r14urbanicity\", \"r15urbanicity\", \"r16urbanicity\",\n",
    "                         \"r12shlt\", \"r13shlt\", \"r14shlt\", \"r15shlt\", \"r16shlt\",\n",
    "                         \"w12os001\", \"w13os001\", \"w14os001\", \"w15os001\", \"w16os001\",\n",
    "                         \"w12os002\", \"w13os002\", \"w14os002\", \"w15os002\", \"w16os002\",\n",
    "                         \"w12os003\", \"w13os003\", \"w14os003\", \"w15os003\", \"w16os003\",\n",
    "                         \"w12os004\", \"w13os004\", \"w14os004\", \"w15os004\", \"w16os004\",\n",
    "                         \"w12os005\", \"w13os005\", \"w14os005\", \"w15os005\", \"w16os005\"]\n",
    "\n",
    "df_comprehensive = df_comprehensive[comprehensive_columns]\n",
    "\n",
    "# Relabel colmns for clarity\n",
    "r12mstat_mapping = {\n",
    "    1: \"Married (Spouse lives with you)\",\n",
    "    2: \"Married (Spouse lives elsewhere)\",\n",
    "    3: \"Separated\",\n",
    "    4: \"Divorced\",\n",
    "    5: \"Widowed\",\n",
    "    6: \"Never Married\"\n",
    "}\n",
    "\n",
    "r12educ_mapping = {\n",
    "    1: \"Less than 1st grade\",\n",
    "    2: \"Up to 4th grade\",\n",
    "    3: \"5th or 6th grade\",\n",
    "    4: \"7th or 8th grade\",\n",
    "    5: \"9th grade\",\n",
    "    6: \"10th grade\",\n",
    "    7: \"11th grade\",\n",
    "    8: \"12th grade-no diploma\",\n",
    "    9: \"High school graduate or GED\",\n",
    "    10: \"Some college-no degree\",\n",
    "    11: \"Assoc. college degree-occ/voc prog\",\n",
    "    12: \"Assoc. college degree-academic prog\",\n",
    "    13: \"Bachelor's degree\",\n",
    "    14: \"Master's degree\",\n",
    "    15: \"Professional school degree\",\n",
    "    16: \"Doctorate degree\"\n",
    "}\n",
    "\n",
    "rarelig_mapping = {\n",
    "    1: \"Protestant\",\n",
    "    2: \"Catholic\",\n",
    "    3: \"Jewish\",\n",
    "    4: \"No religion\",\n",
    "    5: \"Other religion\",\n",
    "}\n",
    "\n",
    "r12laborstatus_mapping = {\n",
    "    1: \"Currently working\",\n",
    "    2: \"On sick or other leave\",\n",
    "    3: \"Unemployed - on layoff\",\n",
    "    4: \"Unemployed - looking\",\n",
    "    5: \"Retired\",\n",
    "    6: \"Disabled\",\n",
    "    7: \"Other Labor Force Status\",\n",
    "    8: \"Mixed\"\n",
    "}\n",
    "\n",
    "r12stateres_mapping = {\n",
    "    1: \"Alabama\", 2: \"Alaska\", 4: \"Arizona\", 5: \"Arkansas\", \n",
    "    6: \"California\", 8: \"Colorado\", 9: \"Connecticut\", 10: \"Delaware\", \n",
    "    11: \"District of Columbia\", 12: \"Florida\", 13: \"Georgia\", 15: \"Hawaii\", \n",
    "    16: \"Idaho\", 17: \"Illinois\", 18: \"Indiana\", 19: \"Iowa\", 20: \"Kansas\",\n",
    "    21: \"Kentucky\", 22: \"Louisiana\", 23: \"Maine\", 24: \"Maryland\", 25: \"Massachusetts\", \n",
    "    26: \"Michigan\", 27: \"Minnesota\", 28: \"Mississippi\", 29: \"Missouri\", 30: \"Montana\",\n",
    "    31: \"Nebraska\", 32: \"Nevada\", 33: \"New Hampshire\", 34: \"New Jersey\", 35: \"New Mexico\",\n",
    "    36: \"New York\", 37: \"North Carolina\", 38: \"North Dakota\", 39: \"Ohio\", 40: \"Oklahoma\", \n",
    "    41: \"Oregon\", 42: \"Pennsylvania\", 44: \"Rhode Island\", 45: \"South Carolina\",\n",
    "    46: \"South Dakota\", 47: \"Tennessee\", 48: \"Texas\", 49: \"Utah\", 50: \"Vermont\", \n",
    "    51: \"Virginia\", 53: \"Washington\", 54: \"West Virginia\", 55: \"Wisconsin\",\n",
    "    56: \"Wyoming\", 60: \"American Samoa\", 66: \"Guam\", 69: \"Northern Mariana Islands\", 72: \"Puerto Rico\",\n",
    "    74: \"U.S. Minor Outlying Islands\", 78: \"Virgin Islands\"\n",
    "}\n",
    "\n",
    "r12urbanicity_mapping = {\n",
    "    1: \"Metropolitan\",\n",
    "    2: \"Micropolitan\",\n",
    "    3: \"Small town/Rural\",\n",
    "    4: \"Unknown\"\n",
    "}\n",
    "\n",
    "r12shlt_mapping = {\n",
    "    1: \"Excellent\",\n",
    "    2: \"Very good\",\n",
    "    3: \"Good\",\n",
    "    4: \"Fair\",\n",
    "    5: \"Poor\"\n",
    "}\n",
    "\n",
    "r12jcoccc_mapping = {    \n",
    "1: \"Management Occupations\",\n",
    "2: \"Business and Financial Operations Occupations\",\n",
    "3: \"Computer and Mathematical Occupations\",\n",
    "4: \"Architecture and Engineering Occupations\",\n",
    "5: \"Life, Physical, and Social Science Occupations\",\n",
    "6: \"Community and Social Service Occupations\",\n",
    "7: \"Legal Occupations\",\n",
    "8: \"Educational Instruction and Library Occupations\",\n",
    "9: \"Arts, Design, Entertainment, Sports, and Media Occupations\",\n",
    "10: \"Healthcare Practitioners and Technical Occupations\",\n",
    "11: \"Healthcare Support Occupations\",\n",
    "12: \"Protective Service Occupations\",\n",
    "13: \"Food Preparation and Serving Related Occupations\",\n",
    "14: \"Building and Grounds Cleaning and Maintenance Occupations\",\n",
    "15: \"Personal Care and Service Occupations\",\n",
    "16: \"Sales and Related Occupations\",\n",
    "17: \"Office and Administrative Support Occupations\",\n",
    "18: \"Farming, Fishing, and Forestry Occupations\",\n",
    "19: \"Construction and Extraction Occupations\",\n",
    "20: \"Installation, Maintenance, and Repair Occupations\",\n",
    "21: \"Production Occupations\",\n",
    "22: \"Transportation and Material Moving Occupations\",\n",
    "23: \"Military Specific Occupations\"\n",
    "}\n",
    "\n",
    "variable_list = [\n",
    "    'r12mstat', 'r13mstat', 'r14mstat', 'r15mstat', 'r16mstat',\n",
    "    'r12educ', 'r13educ', 'r14educ', 'r15educ', 'r16educ',\n",
    "    'rarelig',\n",
    "    'r12laborstatus', 'r13laborstatus', 'r14laborstatus', 'r15laborstatus', 'r16laborstatus',\n",
    "    'r12stateres', 'r13stateres', 'r14stateres', 'r15stateres', 'r16stateres',\n",
    "    'r12jcoccc', 'r13jcoccc', 'r14jcoccc', 'r15jcoccc',\n",
    "    'r12urbanicity', 'r13urbanicity', 'r14urbanicity', 'r15urbanicity', 'r16urbanicity',\n",
    "    'r12shlt', 'r13shlt', 'r14shlt', 'r15shlt', 'r16shlt'\n",
    "]\n",
    "# Map the values in the comprehensive dataset to their descriptive labels\n",
    "for var in variable_list:\n",
    "    if var.endswith('mstat'):\n",
    "        df_comprehensive[var] = df_comprehensive[var].map(r12mstat_mapping)\n",
    "    elif var.endswith('educ'):\n",
    "        df_comprehensive[var] = df_comprehensive[var].map(r12educ_mapping)\n",
    "    elif var == 'rarelig':\n",
    "        df_comprehensive[var] = df_comprehensive[var].map(rarelig_mapping)\n",
    "    elif var.endswith('laborstatus'):\n",
    "        df_comprehensive[var] = df_comprehensive[var].map(r12laborstatus_mapping)\n",
    "    elif var.endswith('stateres'):\n",
    "        df_comprehensive[var] = df_comprehensive[var].map(r12stateres_mapping)\n",
    "    elif var.endswith('jcoccc'):\n",
    "        df_comprehensive[var] = df_comprehensive[var].map(r12jcoccc_mapping)\n",
    "    elif var.endswith('urbanicity'):\n",
    "        df_comprehensive[var] = df_comprehensive[var].map(r12urbanicity_mapping)\n",
    "    elif var.endswith('shlt'):\n",
    "        df_comprehensive[var] = df_comprehensive[var].map(r12shlt_mapping)\n",
    "\n",
    "\n",
    "# Merge the comprehensive file with the abortion dataset\n",
    "df_abortion_comp = df_abortion.merge(df_comprehensive, on=\"uasid\", how=\"left\")\n",
    "\n",
    "# Remove \"only\" from the race column in df_abortion_comp\n",
    "df_abortion_comp['race'] = df_abortion_comp['race'].str.replace(\" Only\", \"\", regex=False)\n",
    "\n",
    "# Remove \"s\" at the end of \"Occupations\" in the rWVjcoccc column\n",
    "df_abortion_comp[\"r12jcoccc\"] = df_abortion_comp[\"r12jcoccc\"].str.replace(\"s$\", \"\", regex=True)\n",
    "df_abortion_comp[\"r13jcoccc\"] = df_abortion_comp[\"r13jcoccc\"].str.replace(\"s$\", \"\", regex=True)\n",
    "df_abortion_comp[\"r14jcoccc\"] = df_abortion_comp[\"r14jcoccc\"].str.replace(\"s$\", \"\", regex=True)\n",
    "df_abortion_comp[\"r15jcoccc\"] = df_abortion_comp[\"r15jcoccc\"].str.replace(\"s$\", \"\", regex=True)\n",
    "\n",
    "# Replace the cells starting with \".\" with None\n",
    "df_abortion_comp = df_abortion_comp.applymap(lambda x: None if str(x).startswith('.') else x)\n",
    "\n",
    "# Remove the number from the cells in num_text_cols\n",
    "num_text_cols = [\"statereside_125\", \"maritalstatus_125\", \"education_125\", \"laborstatus_125\", \"employmenttype_125\", \"abortion_2018_Apr\", \n",
    "                 \"statereside_193\", \"maritalstatus_193\", \"education_193\", \"laborstatus_193\", \"employmenttype_193\", \"abortion_2019_Jul\", \n",
    "                 \"statereside_308\", \"maritalstatus_308\", \"education_308\", \"laborstatus_308\", \"employmenttype_308\", \"abortion_2020_Sep\", \n",
    "                 \"statereside_621\", \"maritalstatus_621\", \"education_621\", \"laborstatus_621\", \"employmenttype_621\", \"abortion_2024_Aug\", \n",
    "                 \"statereside_645\", \"maritalstatus_645\", \"education_645\", \"laborstatus_645\", \"employmenttype_645\", \"abortion_2024_Nov\",              \n",
    "                 \"citizenus\", \"bornus\", \"gender\", \"race\", \"cn001f\", \"hhincome_125\", \"hhincome_193\", \"hhincome_308\", \"hhincome_621\", \"hhincome_645\"]\n",
    "\n",
    "for col in num_text_cols:\n",
    "    df_abortion_comp[col] = df_abortion_comp[col].str.replace(r'^\\d+\\s*', '', regex=True)\n",
    "\n",
    "# Add availability columns for each abortion dataset\n",
    "df_abortion_comp['abortion_2018_Apr_available'] = df_abortion_comp['abortion_2018_Apr'].notna().astype(int)\n",
    "df_abortion_comp['abortion_2019_Jul_available'] = df_abortion_comp['abortion_2019_Jul'].notna().astype(int)\n",
    "df_abortion_comp['abortion_2020_Sep_available'] = df_abortion_comp['abortion_2020_Sep'].notna().astype(int)\n",
    "df_abortion_comp['abortion_2024_Aug_available'] = df_abortion_comp['abortion_2024_Aug'].notna().astype(int)\n",
    "df_abortion_comp['abortion_2024_Nov_available'] = df_abortion_comp['abortion_2024_Nov'].notna().astype(int)\n",
    "\n",
    "# Rename education columns for clarity\n",
    "df_abortion_comp.rename(columns={\n",
    "    \"education_125\": \"edu_2018_Apr\",\n",
    "    \"education_193\": \"edu_2019_Jul\",\n",
    "    \"education_308\": \"edu_2020_Sep\",\n",
    "    \"education_621\": \"edu_2024_Aug\",\n",
    "    \"education_645\": \"edu_2024_Nov\"\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d18279f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1920\n",
      "2008\n"
     ]
    }
   ],
   "source": [
    "print(df_abortion_comp[~df_abortion_comp['dateofbirth_year'].isna()]['dateofbirth_year'].astype(int).min())\n",
    "print(df_abortion_comp[~df_abortion_comp['dateofbirth_year'].isna()]['dateofbirth_year'].astype(int).max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b31a3f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender\n",
       "Female    5001\n",
       "Male      3283\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abortion_comp['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "08be16b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create generation column based on birth year\n",
    "def determine_generation(year):\n",
    "    if pd.isna(year):\n",
    "        return None\n",
    "    year = int(year)\n",
    "    if year <= 1945:\n",
    "        return \"Silent Generation\"\n",
    "    elif 1946 <= year <= 1964:\n",
    "        return \"Baby Boomer\"\n",
    "    elif 1965 <= year <= 1980:\n",
    "        return \"Generation X\"\n",
    "    elif 1981 <= year <= 1996:\n",
    "        return \"Millennial\"\n",
    "    elif 1997 <= year <= 2012:\n",
    "        return \"Generation Z\"\n",
    "    else:\n",
    "        return \"Generation Alpha\"\n",
    "\n",
    "df_abortion_comp['generation'] = df_abortion_comp['dateofbirth_year'].apply(determine_generation)\n",
    "\n",
    "# Create education level column\n",
    "def categorize_education(edu):\n",
    "    if pd.isna(edu):\n",
    "        return None\n",
    "    elif edu in [\n",
    "        \"Less than 1st grade\", \"Up to 4th grade\", \"5th or 6th grade\", \n",
    "        \"7th or 8th grade\", \"9th grade\", \"10th grade\", \"11th grade\", \n",
    "        \"12th grade-no diploma\"\n",
    "    ]:\n",
    "        return \"Less than High School\"\n",
    "    elif edu in [\n",
    "        \"High school graduate or GED\", \"Some college-no degree\", \n",
    "        \"Assoc. college degree-occ/voc prog\", \"Assoc. college degree-academic prog\"\n",
    "    ]:\n",
    "        return \"High School to Associate Degree\"\n",
    "    elif edu == \"Bachelor's degree\":\n",
    "        return \"Bachelor's Degree\"\n",
    "    elif edu in [\n",
    "        \"Master's degree\", \"Professional school degree\", \"Doctorate degree\"\n",
    "    ]:\n",
    "        return \"Graduate Degree\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "df_abortion_comp['edu_level_2018_Apr'] = df_abortion_comp['edu_2018_Apr'].apply(categorize_education)\n",
    "df_abortion_comp['edu_level_2019_Jul'] = df_abortion_comp['edu_2019_Jul'].apply(categorize_education)\n",
    "df_abortion_comp['edu_level_2020_Sep'] = df_abortion_comp['edu_2020_Sep'].apply(categorize_education)\n",
    "df_abortion_comp['edu_level_2024_Aug'] = df_abortion_comp['edu_2024_Aug'].apply(categorize_education)\n",
    "df_abortion_comp['edu_level_2024_Nov'] = df_abortion_comp['edu_2024_Nov'].apply(categorize_education)\n",
    "\n",
    "# Create race group column\n",
    "def categorize_race(race):\n",
    "    if pd.isna(race):\n",
    "        return None\n",
    "    elif race in [\"White\", \"Black\", \"Asian\"]:\n",
    "        return race\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "df_abortion_comp['race'] = df_abortion_comp['race'].apply(categorize_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7d0d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canonical categories (ordered; higher = more pro-choice)\n",
    "CANON = [\"strong_anti\", \"anti\", \"neutral\", \"pro\", \"strong_pro\", \"unsure\"]\n",
    "CANON_CODE = {k:i for i,k in enumerate(CANON)}\n",
    "\n",
    "# EXAMPLE wave→canonical mappings (edit to match your data labels exactly)\n",
    "MAPPINGS = {\n",
    "    # abortion_2018_Apr — support for *anti-abortion* groups (reverse polarity)\n",
    "    \"abortion_2018_Apr\": {\n",
    "        \"Strongly support\": \"strong_anti\",\n",
    "        \"Somewhat support\": \"anti\",\n",
    "        \"Neither support nor oppose\": \"neutral\",\n",
    "        \"Somewhat oppose\": \"pro\",\n",
    "        \"Strongly oppose\": \"strong_pro\",\n",
    "        \"Haven't heard enough\": \"unsure\",\n",
    "    },\n",
    "    # abortion_2019_Jul — Roe v. Wade overturned?\n",
    "    \"abortion_2019_Jul\": {\n",
    "        \"Would like to see Roe v. Wade overturned\": \"strong_anti\",\n",
    "        \"Would not like to see Roe v. Wade overturned\": \"strong_pro\",\n",
    "    },\n",
    "    # abortion_2020_Sep — Legality 4-point\n",
    "    \"abortion_2020_Sep\": {\n",
    "        \"Illegal in all cases\": \"strong_anti\",\n",
    "        \"Illegal in most cases\": \"anti\",\n",
    "        \"Legal in most cases\": \"pro\",\n",
    "        \"Legal in all cases\": \"strong_pro\",\n",
    "    },\n",
    "    # abortion_2024_Aug — allow in first 3 months (Likert)\n",
    "    \"abortion_2024_Aug\": {\n",
    "        \"Strongly disagree\": \"strong_anti\",\n",
    "        \"Disagree\": \"anti\",\n",
    "        \"Slightly disagree\": \"anti\",\n",
    "        \"Neither agree nor disagree\": \"neutral\",\n",
    "        \"Slightly agree\": \"pro\",\n",
    "        \"Agree\": \"pro\",\n",
    "        \"Strongly Agree\": \"strong_pro\",\n",
    "        \"Don't Know\": \"unsure\",\n",
    "    },\n",
    "    # abortion_2024_Nov — importance of access (salience; optional to use)\n",
    "    \"abortion_2024_Nov\": {\n",
    "        \"Not at all important\": \"strong_anti\",\n",
    "        \"Slightly important\": \"anti\",\n",
    "        \"Moderately important\": \"neutral\",\n",
    "        \"Very important\": \"pro\",\n",
    "        \"Extremely important\": \"strong_pro\",\n",
    "    },\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c939646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Harmonize waves and build transitions\n",
    "import json\n",
    "from typing import Dict, List, Optional, Iterable, Tuple\n",
    "\n",
    "def harmonize_waves(\n",
    "    df: pd.DataFrame,\n",
    "    wave_cols: List[str],\n",
    "    mappings: Dict[str, Dict[str, str]],\n",
    "    keep_unsure: bool = True,\n",
    "    suffix_canon: str = \"_canon\",\n",
    "    suffix_code: str = \"_code\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Map each wave column's raw answers to canonical categories and codes.\"\"\"\n",
    "    out = df.copy()\n",
    "    for col in wave_cols:\n",
    "        if col not in out.columns:\n",
    "            continue\n",
    "        m = mappings.get(col, {})\n",
    "        out[col + suffix_canon] = out[col].map(m)\n",
    "        out[col + suffix_code]  = out[col + suffix_canon].map(CANON_CODE)\n",
    "        if not keep_unsure:\n",
    "            # Treat 'unsure' as missing for transitions, keep original columns intact\n",
    "            out.loc[out[col + suffix_canon] == \"unsure\", col + suffix_code] = np.nan\n",
    "    return out\n",
    "\n",
    "def _dirichlet_row_smooth(mat: np.ndarray, alpha: float = 0.25) -> np.ndarray:\n",
    "    mat = np.asarray(mat, dtype=float)\n",
    "    mat = mat + alpha\n",
    "    rowsums = mat.sum(axis=1, keepdims=True)\n",
    "    rowsums = np.where(rowsums <= 0, 1e-12, rowsums)\n",
    "    return mat / rowsums\n",
    "\n",
    "def transitions_between(\n",
    "    df: pd.DataFrame,\n",
    "    from_col_code: str,\n",
    "    to_col_code: str,\n",
    "    weight_col: Optional[str] = None,\n",
    "    valid_codes: Iterable[int] = range(len(CANON)),\n",
    ") -> Dict[str, object]:\n",
    "    \"\"\"\n",
    "    Build a KxK transition matrix between two coded wave columns.\n",
    "    Rows = from, Cols = to. Returns weighted counts, smoothed probs, and row totals.\n",
    "    \"\"\"\n",
    "    K = len(CANON)\n",
    "    mat = np.zeros((K, K), dtype=float)\n",
    "    if weight_col is None or weight_col not in df.columns:\n",
    "        w = np.ones(len(df), dtype=float)\n",
    "    else:\n",
    "        w = df[weight_col].fillna(0).to_numpy(dtype=float)\n",
    "\n",
    "    f = df[from_col_code].to_numpy()\n",
    "    t = df[to_col_code].to_numpy()\n",
    "    mask = (~pd.isna(f)) & (~pd.isna(t))\n",
    "    f = f[mask].astype(int)\n",
    "    t = t[mask].astype(int)\n",
    "    w = w[mask]\n",
    "\n",
    "    for fi, ti, wi in zip(f, t, w):\n",
    "        if (fi in valid_codes) and (ti in valid_codes):\n",
    "            mat[fi, ti] += wi\n",
    "\n",
    "    row_tot = mat.sum(axis=1)\n",
    "    probs = _dirichlet_row_smooth(mat, alpha=0.25)\n",
    "\n",
    "    return {\n",
    "        \"counts\": mat,\n",
    "        \"row_totals\": row_tot,\n",
    "        \"probs\": probs,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9aa8ddb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_grouped_transitions_timevarying_edu(\n",
    "    df: pd.DataFrame,\n",
    "    wave_pairs: List[Tuple[str, str, str, str]],\n",
    "    edu_cols_map: Dict[str, str],\n",
    "    group_cols_static: Optional[List[str]],\n",
    "    weight_col: Optional[str],\n",
    "    question_id: str,\n",
    "    question_text: str,\n",
    "    options: List[str],\n",
    "    out_path: str,\n",
    "    include_edu_in_grouping: bool = True,\n",
    "    # if True, transitions are stratified by edu_t and edu_t1 (finer groups)\n",
    "    # if False, transitions are aggregated but edu_t/edu_t1 values are included as metadata = \"mixed\"\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    For each (from_code_col, to_code_col, year_t, year_t1) pair:\n",
    "      - Attach the correct education columns as edu_t and edu_t1 using edu_cols_map\n",
    "      - Group by static cols (+ optionally edu_t, edu_t1)\n",
    "      - Compute transitions and write JSONL records compatible with T-LLM\n",
    "\n",
    "    Returns: number of records written.\n",
    "    \"\"\"\n",
    "    records = 0\n",
    "    K = len(options)\n",
    "\n",
    "    with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        # If no static grouping, treat whole df as one group\n",
    "        if not group_cols_static:\n",
    "            grouped = [((), df)]\n",
    "        else:\n",
    "            grouped = df.groupby(group_cols_static, dropna=False)\n",
    "\n",
    "        for static_keys, gdf in grouped:\n",
    "            # Build static group meta (sex, age_band, race, etc.)\n",
    "            group_meta_static = {}\n",
    "            if group_cols_static:\n",
    "                if not isinstance(static_keys, tuple):\n",
    "                    static_keys = (static_keys,)\n",
    "                group_meta_static = {c: v for c, v in zip(group_cols_static, static_keys)}\n",
    "\n",
    "            for (from_code_col, to_code_col, year_t, year_t1) in wave_pairs:\n",
    "                if from_code_col not in gdf.columns or to_code_col not in gdf.columns:\n",
    "                    continue\n",
    "\n",
    "                # Determine the education columns for this pair\n",
    "                edu_t_col  = edu_cols_map.get(year_t)\n",
    "                edu_t1_col = edu_cols_map.get(year_t1)\n",
    "\n",
    "                # Prepare a working copy with edu_t / edu_t1 attached\n",
    "                gpair = gdf.copy()\n",
    "                if edu_t_col and (edu_t_col in gpair.columns):\n",
    "                    gpair[\"edu_level_t\"] = gpair[edu_t_col]\n",
    "                else:\n",
    "                    gpair[\"edu_level_t\"] = np.nan\n",
    "\n",
    "                if edu_t1_col and (edu_t1_col in gpair.columns):\n",
    "                    gpair[\"edu_level_t1\"] = gpair[edu_t1_col]\n",
    "                else:\n",
    "                    gpair[\"edu_level_t1\"] = np.nan\n",
    "\n",
    "                # Choose grouping scheme for this pair\n",
    "                if include_edu_in_grouping:\n",
    "                    # stratify by education at t and t+1\n",
    "                    pair_group_cols = [\"edu_level_t\", \"edu_level_t1\"]\n",
    "                    subgroups = gpair.groupby(pair_group_cols, dropna=False)\n",
    "                else:\n",
    "                    # no stratification by education; single aggregated group per static group\n",
    "                    subgroups = [((), gpair)]\n",
    "\n",
    "                for edu_keys, sg in subgroups:\n",
    "                    # Build per-subgroup meta (edu values or 'mixed')\n",
    "                    group_meta = dict(group_meta_static)  # copy\n",
    "                    if include_edu_in_grouping:\n",
    "                        if not isinstance(edu_keys, tuple):\n",
    "                            edu_keys = (edu_keys,)\n",
    "                        group_meta.update({\"edu_level_t\": edu_keys[0], \"edu_level_t1\": edu_keys[1] if len(edu_keys) > 1 else None})\n",
    "                    else:\n",
    "                        group_meta.update({\"edu_level_t\": \"mixed\", \"edu_level_t1\": \"mixed\"})\n",
    "\n",
    "                    # Compute transitions\n",
    "                    trans = transitions_between(\n",
    "                        sg,\n",
    "                        from_col_code=from_code_col,\n",
    "                        to_col_code=to_code_col,\n",
    "                        weight_col=weight_col,\n",
    "                        valid_codes=range(len(options))\n",
    "                    )\n",
    "                    counts = trans[\"counts\"]\n",
    "                    row_tot = trans[\"row_totals\"]\n",
    "                    probs  = trans[\"probs\"]\n",
    "\n",
    "                    # Build JSONL rows\n",
    "                    transition_rows = []\n",
    "                    n_from = {}\n",
    "                    for i in range(K):\n",
    "                        transition_rows.append({\n",
    "                            \"from\": options[i],\n",
    "                            \"to_dist\": probs[i, :].tolist(),\n",
    "                        })\n",
    "                        n_from[options[i]] = float(row_tot[i])\n",
    "\n",
    "                    rec = {\n",
    "                        \"survey_id\": \"UAS\",\n",
    "                        \"year_t\": year_t,\n",
    "                        \"year_t1\": year_t1,\n",
    "                        \"question_id\": question_id,\n",
    "                        \"question_text\": question_text,\n",
    "                        \"options\": options,   # canonical labels\n",
    "                        \"group\": group_meta,  # includes static cols + edu_level_t/edu_level_t1 (or 'mixed')\n",
    "                        \"transition_rows\": transition_rows,\n",
    "                        \"n_from\": n_from\n",
    "                    }\n",
    "                    f.write(json.dumps(rec) + \"\\n\")\n",
    "                    records += 1\n",
    "\n",
    "    return records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d768437e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 1263 transition records.\n"
     ]
    }
   ],
   "source": [
    "# 1) Harmonize waves (as before), then:\n",
    "# Map wave labels to their education columns\n",
    "edu_cols_map = {\n",
    "    \"2018_Apr\": \"edu_level_2018_Apr\",\n",
    "    \"2019_Jul\": \"edu_level_2019_Jul\",\n",
    "    \"2020_Sep\": \"edu_level_2020_Sep\",\n",
    "    \"2024_Aug\": \"edu_level_2024_Aug\",\n",
    "}\n",
    "\n",
    "# Define your (from → to) wave pairs (labels must match keys in edu_cols_map)\n",
    "wave_pairs = [\n",
    "    (\"abortion_2018_Apr_code\", \"abortion_2019_Jul_code\", \"2018_Apr\", \"2019_Jul\"),\n",
    "    (\"abortion_2019_Jul_code\", \"abortion_2020_Sep_code\", \"2019_Jul\", \"2020_Sep\"),\n",
    "    (\"abortion_2020_Sep_code\", \"abortion_2024_Aug_code\", \"2020_Sep\", \"2024_Aug\"),\n",
    "]\n",
    "\n",
    "# Static grouping variables that do NOT change across waves (or that you choose to treat as static):\n",
    "group_cols_static = [\"gender\", \"race\", \"generation\"]\n",
    "\n",
    "# Build JSONL\n",
    "nrecs = build_grouped_transitions_timevarying_edu(\n",
    "    df=df_h,  # your harmonized dataframe with *_code columns\n",
    "    wave_pairs=wave_pairs,\n",
    "    edu_cols_map=edu_cols_map,\n",
    "    group_cols_static=group_cols_static,\n",
    "    weight_col=None,\n",
    "    question_id=\"ABORT_attitude_harmonized\",\n",
    "    question_text=\"Harmonized abortion attitude across waves\",\n",
    "    options=CANON,  # [\"strong_anti\",\"anti\",\"neutral\",\"pro\",\"strong_pro\",\"unsure\"] (or without 'unsure')\n",
    "    out_path=\"TLLM_abortion_transitions_tvEdu.jsonl\",\n",
    "    include_edu_in_grouping=True  # set False to aggregate over education\n",
    ")\n",
    "print(f\"Wrote {nrecs} transition records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5aaacbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"survey_id\": \"UAS\",\n",
      "  \"year_t\": \"2018_Apr\",\n",
      "  \"year_t1\": \"2019_Jul\",\n",
      "  \"question_id\": \"ABORT_attitude_harmonized\",\n",
      "  \"question_text\": \"Harmonized abortion attitude across waves\",\n",
      "  \"options\": [\n",
      "    \"strong_anti\",\n",
      "    \"anti\",\n",
      "    \"neutral\",\n",
      "    \"pro\",\n",
      "    \"strong_pro\",\n",
      "    \"unsure\"\n",
      "  ],\n",
      "  \"group\": {\n",
      "    \"gender\": \"Female\",\n",
      "    \"race\": \"Asian\",\n",
      "    \"generation\": \"Baby Boomer\",\n",
      "    \"edu_level_t\": \"Bachelor's Degree\",\n",
      "    \"edu_level_t1\": \"Bachelor's Degree\"\n",
      "  },\n",
      "  \"transition_rows\": [\n",
      "    {\n",
      "      \"from\": \"strong_anti\",\n",
      "      \"to_dist\": [\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"from\": \"anti\",\n",
      "      \"to_dist\": [\n",
      "        0.1,\n",
      "        0.1,\n",
      "        0.1,\n",
      "        0.1,\n",
      "        0.5,\n",
      "        0.1\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"from\": \"neutral\",\n",
      "      \"to_dist\": [\n",
      "        0.5,\n",
      "        0.05555555555555555,\n",
      "        0.05555555555555555,\n",
      "        0.05555555555555555,\n",
      "        0.2777777777777778,\n",
      "        0.05555555555555555\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"from\": \"pro\",\n",
      "      \"to_dist\": [\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"from\": \"strong_pro\",\n",
      "      \"to_dist\": [\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"from\": \"unsure\",\n",
      "      \"to_dist\": [\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"n_from\": {\n",
      "    \"strong_anti\": 0.0,\n",
      "    \"anti\": 1.0,\n",
      "    \"neutral\": 3.0,\n",
      "    \"pro\": 0.0,\n",
      "    \"strong_pro\": 0.0,\n",
      "    \"unsure\": 0.0\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"survey_id\": \"UAS\",\n",
      "  \"year_t\": \"2018_Apr\",\n",
      "  \"year_t1\": \"2019_Jul\",\n",
      "  \"question_id\": \"ABORT_attitude_harmonized\",\n",
      "  \"question_text\": \"Harmonized abortion attitude across waves\",\n",
      "  \"options\": [\n",
      "    \"strong_anti\",\n",
      "    \"anti\",\n",
      "    \"neutral\",\n",
      "    \"pro\",\n",
      "    \"strong_pro\",\n",
      "    \"unsure\"\n",
      "  ],\n",
      "  \"group\": {\n",
      "    \"gender\": \"Female\",\n",
      "    \"race\": \"Asian\",\n",
      "    \"generation\": \"Baby Boomer\",\n",
      "    \"edu_level_t\": \"High School to Associate Degree\",\n",
      "    \"edu_level_t1\": \"High School to Associate Degree\"\n",
      "  },\n",
      "  \"transition_rows\": [\n",
      "    {\n",
      "      \"from\": \"strong_anti\",\n",
      "      \"to_dist\": [\n",
      "        0.5,\n",
      "        0.1,\n",
      "        0.1,\n",
      "        0.1,\n",
      "        0.1,\n",
      "        0.1\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"from\": \"anti\",\n",
      "      \"to_dist\": [\n",
      "        0.2777777777777778,\n",
      "        0.05555555555555555,\n",
      "        0.05555555555555555,\n",
      "        0.05555555555555555,\n",
      "        0.5,\n",
      "        0.05555555555555555\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"from\": \"neutral\",\n",
      "      \"to_dist\": [\n",
      "        0.5,\n",
      "        0.1,\n",
      "        0.1,\n",
      "        0.1,\n",
      "        0.1,\n",
      "        0.1\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"from\": \"pro\",\n",
      "      \"to_dist\": [\n",
      "        0.1,\n",
      "        0.1,\n",
      "        0.1,\n",
      "        0.1,\n",
      "        0.5,\n",
      "        0.1\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"from\": \"strong_pro\",\n",
      "      \"to_dist\": [\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"from\": \"unsure\",\n",
      "      \"to_dist\": [\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"n_from\": {\n",
      "    \"strong_anti\": 1.0,\n",
      "    \"anti\": 3.0,\n",
      "    \"neutral\": 1.0,\n",
      "    \"pro\": 1.0,\n",
      "    \"strong_pro\": 0.0,\n",
      "    \"unsure\": 0.0\n",
      "  }\n",
      "}\n",
      "{\n",
      "  \"survey_id\": \"UAS\",\n",
      "  \"year_t\": \"2018_Apr\",\n",
      "  \"year_t1\": \"2019_Jul\",\n",
      "  \"question_id\": \"ABORT_attitude_harmonized\",\n",
      "  \"question_text\": \"Harmonized abortion attitude across waves\",\n",
      "  \"options\": [\n",
      "    \"strong_anti\",\n",
      "    \"anti\",\n",
      "    \"neutral\",\n",
      "    \"pro\",\n",
      "    \"strong_pro\",\n",
      "    \"unsure\"\n",
      "  ],\n",
      "  \"group\": {\n",
      "    \"gender\": \"Female\",\n",
      "    \"race\": \"Asian\",\n",
      "    \"generation\": \"Baby Boomer\",\n",
      "    \"edu_level_t\": \"Less than High School\",\n",
      "    \"edu_level_t1\": \"Less than High School\"\n",
      "  },\n",
      "  \"transition_rows\": [\n",
      "    {\n",
      "      \"from\": \"strong_anti\",\n",
      "      \"to_dist\": [\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"from\": \"anti\",\n",
      "      \"to_dist\": [\n",
      "        0.1,\n",
      "        0.1,\n",
      "        0.1,\n",
      "        0.1,\n",
      "        0.5,\n",
      "        0.1\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"from\": \"neutral\",\n",
      "      \"to_dist\": [\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"from\": \"pro\",\n",
      "      \"to_dist\": [\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"from\": \"strong_pro\",\n",
      "      \"to_dist\": [\n",
      "        0.1,\n",
      "        0.1,\n",
      "        0.1,\n",
      "        0.1,\n",
      "        0.5,\n",
      "        0.1\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"from\": \"unsure\",\n",
      "      \"to_dist\": [\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666,\n",
      "        0.16666666666666666\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"n_from\": {\n",
      "    \"strong_anti\": 0.0,\n",
      "    \"anti\": 1.0,\n",
      "    \"neutral\": 0.0,\n",
      "    \"pro\": 0.0,\n",
      "    \"strong_pro\": 1.0,\n",
      "    \"unsure\": 0.0\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Check TLLM_abortion_transitions.jsonl\n",
    "with open(\"TLLM_abortion_transitions_tvEdu.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 3:\n",
    "            break\n",
    "        rec = json.loads(line)\n",
    "        print(json.dumps(rec, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e4bd2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record 1: year_t=2018_Apr, year_t1=2019_Jul, group={'gender': 'Female', 'race': 'Asian', 'generation': 'Baby Boomer', 'edu_level_t': \"Bachelor's Degree\", 'edu_level_t1': \"Bachelor's Degree\"}\n",
      "  Transition Rows:\n",
      "    From: strong_anti, To Dist: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]\n",
      "    From: anti, To Dist: [0.1, 0.1, 0.1, 0.1, 0.5, 0.1]\n",
      "    From: neutral, To Dist: [0.5, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.2777777777777778, 0.05555555555555555]\n",
      "    From: pro, To Dist: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]\n",
      "    From: strong_pro, To Dist: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]\n",
      "    From: unsure, To Dist: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]\n",
      "  N From:\n",
      "    strong_anti: 0.0\n",
      "    anti: 1.0\n",
      "    neutral: 3.0\n",
      "    pro: 0.0\n",
      "    strong_pro: 0.0\n",
      "    unsure: 0.0\n",
      "\n",
      "Record 2: year_t=2018_Apr, year_t1=2019_Jul, group={'gender': 'Female', 'race': 'Asian', 'generation': 'Baby Boomer', 'edu_level_t': 'High School to Associate Degree', 'edu_level_t1': 'High School to Associate Degree'}\n",
      "  Transition Rows:\n",
      "    From: strong_anti, To Dist: [0.5, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "    From: anti, To Dist: [0.2777777777777778, 0.05555555555555555, 0.05555555555555555, 0.05555555555555555, 0.5, 0.05555555555555555]\n",
      "    From: neutral, To Dist: [0.5, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "    From: pro, To Dist: [0.1, 0.1, 0.1, 0.1, 0.5, 0.1]\n",
      "    From: strong_pro, To Dist: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]\n",
      "    From: unsure, To Dist: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]\n",
      "  N From:\n",
      "    strong_anti: 1.0\n",
      "    anti: 3.0\n",
      "    neutral: 1.0\n",
      "    pro: 1.0\n",
      "    strong_pro: 0.0\n",
      "    unsure: 0.0\n",
      "\n",
      "Record 3: year_t=2018_Apr, year_t1=2019_Jul, group={'gender': 'Female', 'race': 'Asian', 'generation': 'Baby Boomer', 'edu_level_t': 'Less than High School', 'edu_level_t1': 'Less than High School'}\n",
      "  Transition Rows:\n",
      "    From: strong_anti, To Dist: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]\n",
      "    From: anti, To Dist: [0.1, 0.1, 0.1, 0.1, 0.5, 0.1]\n",
      "    From: neutral, To Dist: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]\n",
      "    From: pro, To Dist: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]\n",
      "    From: strong_pro, To Dist: [0.1, 0.1, 0.1, 0.1, 0.5, 0.1]\n",
      "    From: unsure, To Dist: [0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]\n",
      "  N From:\n",
      "    strong_anti: 0.0\n",
      "    anti: 1.0\n",
      "    neutral: 0.0\n",
      "    pro: 0.0\n",
      "    strong_pro: 1.0\n",
      "    unsure: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check TLLM_abortion_transitions.jsonl, focusing on transition_rows and n_from\n",
    "with open(\"TLLM_abortion_transitions_tvEdu.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 3:\n",
    "            break\n",
    "        rec = json.loads(line)\n",
    "        print(f\"Record {i+1}: year_t={rec['year_t']}, year_t1={rec['year_t1']}, group={rec['group']}\")\n",
    "        print(\"  Transition Rows:\")\n",
    "        for row in rec['transition_rows']:\n",
    "            print(f\"    From: {row['from']}, To Dist: {row['to_dist']}\")\n",
    "        print(\"  N From:\")\n",
    "        for k, v in rec['n_from'].items():\n",
    "            print(f\"    {k}: {v}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cded3330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generation\n",
       "Baby Boomer          2798\n",
       "Generation X         2507\n",
       "Millennial           2186\n",
       "Silent Generation     410\n",
       "Generation Z          378\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_abortion_comp['generation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d0a3ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708a4349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31583a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba34eca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
